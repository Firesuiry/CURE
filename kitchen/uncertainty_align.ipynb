{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "TEST_FLAG = os.getenv('TEST_FLAG', '0') == '1'\n",
    "cache_dir = os.getenv('CACHE_DIR', '0')\n",
    "if cache_dir == \"0\":\n",
    "    cache_dir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown A few imports and downloading data\n",
    "# !pip install -U --no-cache-dir gdown --pre\n",
    "# !pip install openai tqdm\n",
    "!export HF_ENDPOINT=https://hf-mirror.com\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "# import openai\n",
    "import signal\n",
    "import tqdm.notebook as tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import pdb\n",
    "import pickle\n",
    "# dataset files - small sizes\n",
    "# !gdown https://drive.google.com/uc?id=1XWIeGfF08V1eR104VLDilmwhIGVk2uzk\n",
    "# !gdown https://drive.google.com/uc?id=1iEIZaVbbajMXsNdrjVkOgK5rhPtfl5WI\n",
    "\n",
    "# Set OpenAI API key.\n",
    "# openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ENSEMBLE= 5\n",
    "if TEST_FLAG:\n",
    "    NUM_ENSEMBLE = 1\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20237c4c04647c4befbbd7ca811e9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation.logits_process import InfNanRemoveLogitsProcessor\n",
    "from transformers import LogitsProcessorList, LogitsProcessor\n",
    "import torch\n",
    "from llm_llma import LLAMA\n",
    "\n",
    "try:\n",
    "    llama_obj\n",
    "except:\n",
    "    model_name = \"unsloth/Llama-3.3-70B-Instruct\"\n",
    "    if TEST_FLAG:\n",
    "        model_name = \"voidful/Llama-3.2-8B-Instruct\"\n",
    "    llama_obj = LLAMA(model_name, load_in_8bit=True, cache_dir=cache_dir)\n",
    "    llama = llama_obj.llama\n",
    "\n",
    "    tokenizer = llama_obj.tokenizer\n",
    "    class RestrictTokenLogitsProcessor(LogitsProcessor):\n",
    "        def __init__(self, tokenizer, allowed_tokens):\n",
    "            self.allowed_token_ids = tokenizer.convert_tokens_to_ids(allowed_tokens)\n",
    "\n",
    "        def __call__(self, input_ids, scores):\n",
    "            # Set logits of all tokens except the allowed ones to -inf\n",
    "            forbidden_tokens_mask = torch.ones_like(scores).bool()\n",
    "            forbidden_tokens_mask[:, self.allowed_token_ids] = False\n",
    "            scores[forbidden_tokens_mask] = float('-inf')\n",
    "            return scores\n",
    "\n",
    "    allowed_tokens = ['A', 'B', 'C', 'D', 'E']\n",
    "    allowed_token_ids = tokenizer.convert_tokens_to_ids(allowed_tokens)\n",
    "    processors = LogitsProcessorList([\n",
    "        RestrictTokenLogitsProcessor(tokenizer, allowed_tokens),\n",
    "        InfNanRemoveLogitsProcessor()  # Removes inf/nan values to prevent errors during generation\n",
    "    ])\n",
    "\n",
    "    yes_no_processors = LogitsProcessorList([\n",
    "        RestrictTokenLogitsProcessor(tokenizer, ['Yes', 'No']),\n",
    "        InfNanRemoveLogitsProcessor()  # Removes inf/nan values to prevent errors during generation\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded scenario info from ./content/metabot-tasks-info.txt\n",
      "Sample scenario:\n",
      "\n",
      "Scene: a Coke, a bottled unsweetened tea, and a Sprite\n",
      "Task: Bring me a flavored drink.\n",
      "User intent (object): Coke, bottled unsweetened tea, Sprite\n",
      "User intent (location): pick-up\n",
      "Scene objects: Coke, bottled unsweetened tea, Sprite\n",
      "Task category: creative_multilabel_task\n",
      "300\n",
      "{'index': 0, 'scene': 'a Coke, a bottled unsweetened tea, and a Sprite', 'task': 'Bring me a flavored drink.', 'user_intent_object': 'Coke, bottled unsweetened tea, Sprite', 'user_intent_location': 'pick-up', 'scene_objects': 'Coke, bottled unsweetened tea, Sprite', 'task_category': 'creative_multilabel_task'}\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "# Load the 300 scenarios\n",
    "run_flag = True\n",
    "try:\n",
    "    scenario_data\n",
    "    run_flag = False\n",
    "except NameError:\n",
    "  pass\n",
    "\n",
    "if run_flag:\n",
    "  scenario_info_path = './content/metabot-tasks-info.txt'\n",
    "  with open(scenario_info_path, 'r') as f:\n",
    "    scenario_info_text = f.read()\n",
    "  scenario_info_text = scenario_info_text.split('\\n\\n')\n",
    "  print('Loaded scenario info from ' + scenario_info_path)\n",
    "  #@title\n",
    "  # Print a scenario\n",
    "  print('Sample scenario:\\n')\n",
    "  print(scenario_info_text[0].split('\\n',1)[1])  # remove the printed index\n",
    "  '''\n",
    "  Scene: a Coke, a bottled unsweetened tea, and a Sprite\n",
    "  Task: Bring me a flavored drink.\n",
    "  User intent (object): Coke, bottled unsweetened tea, Sprite\n",
    "  User intent (location): pick-up\n",
    "  Scene objects: Coke, bottled unsweetened tea, Sprite\n",
    "  Task category: creative_multilabel_task'''\n",
    "\n",
    "  scenario_data = []\n",
    "  for scenario in scenario_info_text:\n",
    "    if len(scenario.split('\\n')) < 7:\n",
    "      continue\n",
    "    index = int(scenario.split('\\n')[0])\n",
    "    scenario = scenario.split('\\n')[1:]\n",
    "    scene = scenario[0].split('Scene: ')[1]\n",
    "    task = scenario[1].split('Task: ')[1]\n",
    "    user_intent_object = scenario[2].split('User intent (object): ')[1]\n",
    "    user_intent_location = scenario[3].split('User intent (location): ')[1]\n",
    "    scene_objects = scenario[4].split('Scene objects: ')[1]\n",
    "    task_category = scenario[5].split('Task category: ')[1]\n",
    "    scenario_data.append({\n",
    "          'index': index,\n",
    "          'scene': scene,\n",
    "          'task': task,\n",
    "          'user_intent_object': user_intent_object,\n",
    "          'user_intent_location': user_intent_location,\n",
    "          'scene_objects': scene_objects,\n",
    "          'task_category': task_category\n",
    "    })\n",
    "    # if debug:\n",
    "    #   if len(scenario_data) > 1:\n",
    "    #     break\n",
    "  print(len(scenario_data))\n",
    "  print(scenario_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scence = '''You are a robot operating in an office kitchen. \n",
    "You are in front of a counter with two closed drawers, a top one and a bottom one. \n",
    "There is also a landfill bin, a recycling bin, and a compost bin.\n",
    "'''.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Yes': 1.0, 'No': 0.0}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = llama_obj.tokenizer\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "def chat(messages, max_length=1000, temperature=0.0, do_sample=True):\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(llama_obj.device)\n",
    "    decode_outputs = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "    outputs = llama_obj.model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=max_length,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=do_sample,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "    response = tokenizer.decode(response, skip_special_tokens=True)\n",
    "    messages.append({\n",
    "        'role': 'assistant',\n",
    "        'content': response\n",
    "    })\n",
    "    return response, messages\n",
    "\n",
    "def chat_with_score(messages, max_length=1, allowed_token_ids=['Yes', 'No']):\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(llama_obj.device)\n",
    "    logits_processor = LogitsProcessorList([\n",
    "    RestrictTokenLogitsProcessor(tokenizer, allowed_token_ids),\n",
    "    InfNanRemoveLogitsProcessor()  # Removes inf/nan values to prevent errors during generation\n",
    "    ])\n",
    "    outputs = llama_obj.model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=max_length,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        logits_processor=logits_processor,\n",
    "        output_scores=True,\n",
    "        return_dict_in_generate=True, \n",
    "    )\n",
    "    last_token_logits = outputs.scores[-1]\n",
    "    last_token_logits = last_token_logits.detach().cpu()\n",
    "    probs = torch.softmax(last_token_logits, dim=-1)\n",
    "\n",
    "    all_tokens = ['Yes', 'No']\n",
    "    allowed_token_ids = tokenizer.convert_tokens_to_ids(all_tokens)\n",
    "    token_probs = {}\n",
    "    for j in range(len(all_tokens)):\n",
    "        log_prob = probs[0, allowed_token_ids[j]].item()\n",
    "        token_probs[all_tokens[j]] = log_prob\n",
    "    return token_probs\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': 'You are a assistent, please reply according to the user\\'s request.'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': '1+1=2?say Yes or No'\n",
    "    }\n",
    "]\n",
    "print(chat_with_score(messages, max_length=1, allowed_token_ids=['Yes', 'No']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla 方法输出不确定性\n",
    "vanilla_prompt = '''\n",
    "provide what will you do and your confidence in this answer. \n",
    "Note: The confidence indicates how likely you think what will you do is true. \n",
    "Note: The action you take should be one of [pick-up, bring, move, open, close] and something you seen(should be a single full name) [to where(should be a single full name) you seen if needed].\n",
    "Use the following format to answer: \n",
    "\"Action:[What will you do]\n",
    "Confidence: [Your confidence level, please only include the numerical number in the range of 0-100]%\"\n",
    "Only the answer and confidence, don't give me the explanation.  \n",
    "Now, please answer this question and provide your confidence level.\n",
    "'''\n",
    "def prompt_vanilla(data, sample_num=1, sample_mode='greedy', print_flag = False):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": all_scence},\n",
    "        {\"role\": \"user\", \"content\": \"On the counter, there is {scene}\".format(scene=data[\"scene\"])},\n",
    "        {\"role\": \"user\", \"content\": \"{task}\".format(task=data[\"task\"])},\n",
    "        {\"role\": \"user\", \"content\": vanilla_prompt},\n",
    "    ]\n",
    "    response, messages = chat(messages, max_length=1000)\n",
    "\n",
    "    if print_flag:print(response)\n",
    "    for line in response.split('\\n'):\n",
    "        if 'Action:' in line:\n",
    "            output_action = line.split('Action:')[1].strip()\n",
    "        if 'Confidence:' in line:\n",
    "            output_confidence = float(line.split('Confidence:')[1].strip().replace('%', ''))/100\n",
    "    \n",
    "    vanilla_output = {\n",
    "        'action': output_action,\n",
    "        'confidence': output_confidence\n",
    "    }\n",
    "    return vanilla_output\n",
    "def collect_vanilla_outputs(prompt_vanilla, data, force_rerun=False, num_ensemble=NUM_ENSEMBLE):\n",
    "    if 'vanilla_output' in data and not force_rerun:\n",
    "        return\n",
    "    print(f'scene: {data[\"scene\"]}\\ntask: {data[\"task\"]}\\n')\n",
    "    all_outputs = []\n",
    "    for i in range(num_ensemble):\n",
    "        vanilla_output = prompt_vanilla(data)\n",
    "        all_outputs.append(vanilla_output)\n",
    "    print(f'scene: {data[\"scene\"]}\\ntask: {data[\"task\"]}\\nvanilla_output: {vanilla_output}\\n')\n",
    "    print('-'*100)\n",
    "    data['vanilla_output'] = all_outputs\n",
    "\n",
    "\n",
    "# data = scenario_data[128]\n",
    "# collect_vanilla_outputs(prompt_vanilla, data, force_rerun=True, num_ensemble=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COT 方法输出不确定性\n",
    "cot_prompt = '''\n",
    "analyze step by step, provide your what will you do and your confidence in this answer. \n",
    "'''\n",
    "cot_prompt = '''\n",
    "analyze step by step, provide what will you do and your confidence in this answer. \n",
    "Note: The confidence indicates how likely you think your action is true. Use the following format to answer: \n",
    "\"Explanation: [insert step-by-step analysis here] \n",
    "Action:[What will you do Here]\n",
    "Confidence:[Your confidence level, please only include the numerical number in the range of 0-100]%\"\n",
    "Note: The action you take should be one of [pick-up, bring, move, open, close] and something you seen(should be a single full name) [to where(should be a single full name) you seen if needed].\n",
    "Only give me the reply according to this format, don't give me any other words. \n",
    "Now, please answer this question and provide your confidence level. Let's think it step by step.\n",
    "'''\n",
    "def prompt_cot(data, sample_num=1, sample_mode='greedy'):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": all_scence},\n",
    "        {\"role\": \"user\", \"content\": \"On the counter, there is {scene}\".format(scene=data[\"scene\"])},\n",
    "        {\"role\": \"user\", \"content\": \"{task}\".format(task=data[\"task\"])},\n",
    "        {\"role\": \"user\", \"content\": cot_prompt},\n",
    "    ]\n",
    "    response, messages = chat(messages, max_length=1000)\n",
    "    messages_for_confidence = copy.deepcopy(messages)\n",
    "    print(response)\n",
    "    for line in response.split('\\n'):\n",
    "        if 'Action:' in line:\n",
    "            output_action = line.split('Action:')[1].strip()\n",
    "        if 'Confidence:' in line:\n",
    "            output_confidence = float(line.split('Confidence:')[1].strip().replace('%', ''))/100\n",
    "    \n",
    "    cot_output = {\n",
    "        'action': output_action,\n",
    "        'confidence': output_confidence\n",
    "    }\n",
    "    return cot_output\n",
    "\n",
    "\n",
    "def collect_cot_output(data, force_rerun=False, num_ensemble=NUM_ENSEMBLE):\n",
    "    if 'cot_output' in data and not force_rerun:\n",
    "        return\n",
    "    all_outputs = []\n",
    "    for i in range(num_ensemble):\n",
    "        cot_output = prompt_cot(data)\n",
    "        all_outputs.append(cot_output)\n",
    "    print(f'scene: {data[\"scene\"]}\\ntask: {data[\"task\"]}\\ncot_output: {cot_output}\\n')\n",
    "    print('-'*100)\n",
    "    data['cot_output'] = all_outputs\n",
    "\n",
    "# data = scenario_data[128]\n",
    "# collect_cot_output(data, force_rerun=True, num_ensemble=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_probing_prompt = '''\n",
    "What will you do? \n",
    "Note: The action you take should be one of [pick-up, bring, move, open, close] and something you seen(should be a single full name) [to where(should be a single full name) you seen if needed].\n",
    "'''\n",
    "def prompt_self_probing(data, sample_num=1, sample_mode='greedy'):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": all_scence},\n",
    "        {\"role\": \"user\", \"content\": \"On the counter, there is {scene}\".format(scene=data[\"scene\"])},\n",
    "        {\"role\": \"user\", \"content\": \"{task}\".format(task=data[\"task\"])},\n",
    "        {\"role\": \"user\", \"content\": self_probing_prompt},\n",
    "    ]\n",
    "    print(messages)\n",
    "    response, messages = chat(messages, max_length=1000)\n",
    "    messages_for_confidence = copy.deepcopy(messages)\n",
    "    messages_for_confidence2 = copy.deepcopy(messages)\n",
    "    print(response)\n",
    "    output_action = response\n",
    "    messages_for_confidence.append({\n",
    "        'role': 'user',\n",
    "        'content': 'according to your response, what is your confidence in this action? reply with the confidence only. the confidence should be a percentage.'\n",
    "    })\n",
    "    response, messages_for_confidence = chat(messages_for_confidence, max_length=1000)\n",
    "    print('*'*100)\n",
    "    print(response)\n",
    "    output_confidence = float(response.split('%')[0])/100\n",
    "    cot_output = {\n",
    "        'action': output_action,\n",
    "        'confidence': output_confidence\n",
    "    }\n",
    "    # confidence collect with yes/no logits\n",
    "    messages_for_confidence2.append({\n",
    "        'role': 'user',\n",
    "        'content': 'according to your response, do you think your action is correct? reply with Yes or No.'\n",
    "    })\n",
    "    res = chat_with_score(messages_for_confidence2, max_length=1, allowed_token_ids=['Yes', 'No'])\n",
    "    print(res)\n",
    "    confidence = res['Yes']\n",
    "    print(f'log confidence: {confidence}')\n",
    "    cot_output['log_confidence'] = confidence\n",
    "    return cot_output\n",
    "\n",
    "def collect_self_prob_outputs(data, force_rerun=False, num_ensemble=NUM_ENSEMBLE):\n",
    "    if 'self_probing_output' in data and not force_rerun:\n",
    "        return\n",
    "    all_outputs = []\n",
    "    all_outputs_log = []\n",
    "    for i in range(num_ensemble):\n",
    "        self_probing_output = prompt_self_probing(data)\n",
    "        self_probing_output_log = copy.deepcopy(self_probing_output)\n",
    "\n",
    "        del self_probing_output['log_confidence']\n",
    "        all_outputs.append(self_probing_output)\n",
    "        \n",
    "        self_probing_output_log['confidence'] = self_probing_output_log['log_confidence']\n",
    "        del self_probing_output_log['log_confidence']\n",
    "        all_outputs_log.append(self_probing_output_log)\n",
    "    print(f'scene: {data[\"scene\"]}\\ntask: {data[\"task\"]}\\nself_probing_output: {self_probing_output}\\n')\n",
    "    print('-'*100)\n",
    "    data['self_probing_output'] = all_outputs\n",
    "    data['self_probing_output_log'] = all_outputs_log\n",
    "\n",
    "\n",
    "# data = scenario_data[0]\n",
    "# collect_self_prob_outputs(data, force_rerun=True, num_ensemble=1)\n",
    "# print(data['self_probing_output'])\n",
    "# print(data['self_probing_output_log'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_step_prompt = '''\n",
    "What will you do? only interact with the objects in the scene.\n",
    "Read the question, break down the problem into K steps, think step by step, \n",
    "give your confidence in each step, and then derive your final answer and your confidence in this answer. \n",
    "Note: The confidence indicates how likely you think your answer is true. \n",
    "Use the following format to answer: \n",
    "\"Step 1: [Your reasoning], Confidence: [ONLY the confidence value that this step is correct]% \n",
    "... \n",
    "Step K: [Your reasoning], Confidence: [ONLY the confidence value that this step is correct]% \n",
    "Final Answer and Overall Confidence (0-100): [ONLY the answer type; not a complete sentence], [Your confidence value]%\"\n",
    "'''\n",
    "def prompt_multi_step(data, sample_num=1, sample_mode='greedy'):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": all_scence},\n",
    "        {\"role\": \"user\", \"content\": \"On the counter, there is {scene}\".format(scene=data[\"scene\"])},\n",
    "        {\"role\": \"user\", \"content\": \"{task}\".format(task=data[\"task\"])},\n",
    "        {\"role\": \"user\", \"content\": multi_step_prompt},\n",
    "    ]\n",
    "    print(messages)\n",
    "    response, messages = chat(messages, max_length=1000)\n",
    "    messages_for_confidence = copy.deepcopy(messages)\n",
    "    response_for_confidence = response\n",
    "    print(response)\n",
    "    messages.append({\n",
    "        'role': 'user',\n",
    "        'content': 'according to your response, what action will you do? reply with the action only.Note: The action you take should be one of [pick-up, bring, move, open, close] and something you seen(should be a single full name) [to where(should be a single full name) you seen if needed].'\n",
    "    })\n",
    "    response, messages = chat(messages, max_length=1000)\n",
    "    print('*'*100)\n",
    "    print(response)\n",
    "    output_action = response\n",
    "    \n",
    "    confidence = 1\n",
    "    ress = response_for_confidence.split('Step ')\n",
    "    for res in ress:\n",
    "        if not '%' in res:\n",
    "            continue\n",
    "        res = res.split('%')[0]\n",
    "        confidence *= float(res.split(':')[-1])/100\n",
    "    output_confidence = confidence\n",
    "\n",
    "    cot_output = {\n",
    "        'action': output_action,\n",
    "        'confidence': output_confidence\n",
    "    }\n",
    "    return cot_output\n",
    "\n",
    "def collect_multi_step_output(data, force_rerun=False, num_ensemble=NUM_ENSEMBLE):\n",
    "    if 'multi_step_output' in data and not force_rerun:\n",
    "        return\n",
    "    all_outputs = []\n",
    "    for i in range(num_ensemble):\n",
    "        multi_step_output = prompt_multi_step(data)\n",
    "        all_outputs.append(multi_step_output)\n",
    "    print(f'scene: {data[\"scene\"]}\\ntask: {data[\"task\"]}\\nmulti_step_output: {multi_step_output}\\n')\n",
    "    print('-'*100)\n",
    "    data['multi_step_output'] = all_outputs\n",
    "\n",
    "# data = scenario_data[128]\n",
    "# collect_multi_step_output(data, force_rerun=True, num_ensemble=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_prompt = '''\n",
    "What will you do? only interact with the objects in the scene.\n",
    "Provide your k best guesses and the probability that each is correct (0% to 100%) for the following question. \n",
    "Give ONLY the task output description of your guesses and probabilities, no other words or explanation. \n",
    "Note: The action you take should be one of [pick-up, bring, move, open, close] and something you seen(should be a single full name) [to where(should be a single full name) you seen if needed].\n",
    "For example: \n",
    "G1: <ONLY the action description of first most likely guess; not a complete sentence, just the guess!> \n",
    "P1: <ONLY the probability that G1 is correct, without any extra commentary whatsoever; just the probability!> \n",
    "... \n",
    "Gk: <ONLY the action description of k-th most likely guess> \n",
    "Pk: <ONLY the probability that Gk is correct, without any extra commentary whatsoever; just the probability!>\n",
    "'''\n",
    "def prompt_top_k(data, sample_num=1, sample_mode='greedy'):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": all_scence},\n",
    "        {\"role\": \"user\", \"content\": \"On the counter, there is {scene}\".format(scene=data[\"scene\"])},\n",
    "        {\"role\": \"user\", \"content\": \"{task}\".format(task=data[\"task\"])},\n",
    "        {\"role\": \"user\", \"content\": top_k_prompt},\n",
    "    ]\n",
    "    response, messages = chat(messages, max_length=1000)\n",
    "    print(response)\n",
    "    '''\n",
    "    G1: Bring the Coke\n",
    "    P1: 60%\n",
    "\n",
    "    G2: Bring the Sprite\n",
    "    P2: 20%\n",
    "\n",
    "    G3: Bring the bottled unsweetened tea\n",
    "    P3: 20%\n",
    "    '''\n",
    "    # split the response into G1, P1, G2, P2, ...\n",
    "    top_k_result = {}\n",
    "    response = response.split('\\n')\n",
    "    for i in range(len(response)):\n",
    "        if response[i].startswith('G') or response[i].startswith('P'):\n",
    "            index = int(response[i].split(':')[0][1:])\n",
    "            if index not in top_k_result:\n",
    "                top_k_result[index] = {}\n",
    "\n",
    "        if response[i].startswith('P'):\n",
    "            confidence = float(response[i].split(':')[-1].strip().split('%')[0])/100\n",
    "            top_k_result[index]['confidence'] = confidence\n",
    "        elif response[i].startswith('G'):\n",
    "            top_k_result[index]['action']= response[i].split(':')[-1].strip()\n",
    "\n",
    "    output_action = ''\n",
    "    output_confidence = -9999\n",
    "    for k, v in top_k_result.items():\n",
    "        if v['confidence'] > output_confidence:\n",
    "            output_action = v['action']\n",
    "            output_confidence = v['confidence']\n",
    "\n",
    "    cot_output = {\n",
    "        'action': output_action,\n",
    "        'confidence': output_confidence,\n",
    "        'all_result': top_k_result\n",
    "    }\n",
    "    return cot_output\n",
    "\n",
    "\n",
    "def collect_top_k_outputs(data, force_rerun=False, num_ensemble=NUM_ENSEMBLE):\n",
    "    if 'top_k_output' in data and not force_rerun:\n",
    "        return\n",
    "    all_outputs = []\n",
    "    for i in range(num_ensemble):\n",
    "        top_k_output = prompt_top_k(data)\n",
    "        all_outputs.append(top_k_output)\n",
    "    print(f'scene: {data[\"scene\"]}\\ntask: {data[\"task\"]}\\ntop_k_output: {top_k_output}\\n')\n",
    "    print('-'*100)\n",
    "    data['top_k_output'] = all_outputs\n",
    "\n",
    "# data = scenario_data[128]\n",
    "# collect_top_k_outputs(data, force_rerun=True, num_ensemble=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def process_mc_raw(mc_raw, add_mc='an option not listed here'):\n",
    "    mc_all = mc_raw.split('\\n')\n",
    "    mc_processed_all = []\n",
    "    for mc in mc_all:\n",
    "        mc = mc.strip()  # sometimes there is leading space\n",
    "    # skip nonsense\n",
    "        if len(mc) < 5 or mc[0] not in [\n",
    "        'a', 'b', 'c', 'd', 'A', 'B', 'C', 'D', '1', '2', '3', '4'\n",
    "    ]:\n",
    "            continue\n",
    "        mc = mc[2:]  # remove a), b), ...\n",
    "        mc = mc.strip().lower().split('.')[0]\n",
    "        mc_processed_all.append(mc)\n",
    "    if len(mc_processed_all) < 4:\n",
    "        raise 'Cannot extract four options from the raw output.'\n",
    "# Check if any repeated option - use do nothing as substitue\n",
    "    mc_processed_all = list(set(mc_processed_all))\n",
    "    if len(mc_processed_all) < 4:\n",
    "        num_need = 4 - len(mc_processed_all)\n",
    "        for _ in range(num_need):\n",
    "            mc_processed_all.append('do nothing')\n",
    "    prefix_all = ['A) ', 'B) ', 'C) ', 'D) ']\n",
    "    if add_mc is not None:\n",
    "        mc_processed_all.append(add_mc)\n",
    "        prefix_all.append('E) ')\n",
    "    random.shuffle(mc_processed_all)\n",
    "    mc_prompt = ''\n",
    "    for mc_ind, (prefix, mc) in enumerate(zip(prefix_all, mc_processed_all)):\n",
    "        mc_prompt += prefix + mc\n",
    "        if mc_ind < len(mc_processed_all) - 1:\n",
    "            mc_prompt += '\\n'\n",
    "    add_mc_prefix = prefix_all[mc_processed_all.index(add_mc)][0]\n",
    "    return mc_prompt, mc_processed_all, add_mc_prefix\n",
    "\n",
    "def temperature_scaling(logits, temperature):\n",
    "    logits = np.array(logits)\n",
    "    logits /= temperature\n",
    "\n",
    "# apply softmax\n",
    "    logits -= logits.max()\n",
    "    logits = logits - np.log(np.sum(np.exp(logits)))\n",
    "    smx = np.exp(logits)\n",
    "    return smx\n",
    "\n",
    "demo_mc_gen_prompt0 = \"\"\"\n",
    "We: You are a robot operating in an office kitchen. You are in front of a counter with two closed drawers, a top one and a bottom one. There is also a landfill bin, a recycling bin, and a compost bin.\n",
    "We: On the counter, there is an orange soda, a Pepsi, and an apple.\n",
    "We: Put that drink in the top drawer.\n",
    "You:\n",
    "A) open the top drawer and put the orange soda in it\n",
    "B) open the bottom drawer and put the Pepsi in it\n",
    "C) open the bottom drawer and put the orange soda in it\n",
    "D) open the top drawer and put the Pepsi in it\n",
    "We: On the counter, there is an energy bar, a banana, and a microwave.\n",
    "We: Put the snack next to the microwave.\n",
    "You:\n",
    "A) pick up the energy bar and put it next to the microwave\n",
    "B) pick up the banana and put it next to the energy bar\n",
    "C) pick up the banana and put it next to the microwave\n",
    "D) pick up the energy bar and put it next to the banana\n",
    "We: On the counter, there is a Coke, a Sprite, and a sponge.\n",
    "We: Can you dispose of the can? It should have expired.\n",
    "You:\n",
    "A) pick up the sponge and put it in the landfill bin\n",
    "B) pick up the Coke and put it in the recycling bin\n",
    "C) pick up the Sprite and put it in the recycling bin\n",
    "D) pick up the Coke and put it in the landfill bin\n",
    "We: On the counter, there is a bottled water, a bag of jalapeno chips, and a bag of rice chips.\n",
    "We: I would like a bag of chips.\n",
    "You:\n",
    "A) pick up the bottled water\n",
    "B) pick up the jalapeno chips\n",
    "C) pick up the kettle chips\n",
    "D) pick up the rice chips\n",
    "We: On the counter, there is {scene_objects}\n",
    "We: {task}\n",
    "You:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# conformal prediction 方法输出不确定性\n",
    "def generate_multiple_choice(data):\n",
    "    instruction = data['task']\n",
    "    scene_objects = data['scene_objects']\n",
    "    result = {}\n",
    "    # skip_calibration = False #@param {type:\"boolean\"}\n",
    "    # if skip_calibration: qhat = 0.928 # based on epsilon=0.2\n",
    "\n",
    "    demo_mc_gen_prompt = demo_mc_gen_prompt0\n",
    "# prompt for generating multiple choice\n",
    "    demo_mc_gen_prompt = demo_mc_gen_prompt.replace('{task}', instruction)\n",
    "    demo_mc_gen_prompt = demo_mc_gen_prompt.replace('{scene_objects}', scene_objects)\n",
    "\n",
    "# Generate multiple choices\n",
    "    _, demo_mc_gen_raw = llama(demo_mc_gen_prompt, stop_seq=['\\n\\n', 'We:'])\n",
    "    demo_mc_gen_raw = demo_mc_gen_raw.strip()\n",
    "    demo_mc_gen_full, demo_mc_gen_all, demo_add_mc_prefix = process_mc_raw(demo_mc_gen_raw)\n",
    "\n",
    "# get the part of the current scenario from the previous prompt\n",
    "    demo_cur_scenario_prompt = demo_mc_gen_prompt.split('\\n\\n')[-1].strip()\n",
    "\n",
    "# get new prompt\n",
    "    demo_mc_score_background_prompt = \"\"\"\n",
    "    You are a robot operating in an office kitchen. You are in front of a counter with two closed drawers, a top one and a middle one. There is also a landfill bin, a recycling bin, and a compost bin.\n",
    "    \"\"\".strip()\n",
    "    demo_mc_score_prompt = demo_mc_score_background_prompt + '\\n\\n' + demo_cur_scenario_prompt + '\\n' + demo_mc_gen_full\n",
    "    demo_mc_score_prompt += \"\\nWe: Which option is correct? Answer with a single capital letter.\"\n",
    "    demo_mc_score_prompt += \"\\nYou:\"\n",
    "\n",
    "# scoring\n",
    "# mc_score_response, _ = lm(demo_mc_score_prompt, max_tokens=1, logprobs=5)\n",
    "# top_logprobs_full = mc_score_response[\"choices\"][0][\"logprobs\"][\"top_logprobs\"][0]\n",
    "# top_tokens = [token.strip() for token in top_logprobs_full.keys()]\n",
    "# top_logprobs = [value for value in top_logprobs_full.values()]\n",
    "\n",
    "\n",
    "# scoring with llama-----------------------------------------------------\n",
    "    mc_score_response, response = llama(demo_mc_score_prompt, max_length=1, output_scores=True, processors=processors)\n",
    "\n",
    "# Get the logits of the last token generated\n",
    "    last_token_logits = mc_score_response.scores[-1]\n",
    "    last_token_logits = last_token_logits.detach().cpu()\n",
    "\n",
    "# Apply softmax to convert logits to probabilities\n",
    "    probs = torch.softmax(last_token_logits, dim=-1)\n",
    "    log_probs = torch.log(probs)\n",
    "\n",
    "# Extract probabilities for 'A', 'B', 'C'\n",
    "    all_tokens = ['A', 'B', 'C', 'D', 'E']\n",
    "    allowed_token_ids = tokenizer.convert_tokens_to_ids(all_tokens)\n",
    "    token_probs = []\n",
    "    for i in range(len(all_tokens)):\n",
    "        log_prob = log_probs[0, allowed_token_ids[i]].item()\n",
    "        token_probs.append((all_tokens[i], log_prob))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# Collect and sort probabilities\n",
    "    sorted_token_probs = sorted(token_probs, key=lambda x: x[1], reverse=True)\n",
    "    top_tokens = [tuple[0] for tuple in sorted_token_probs]\n",
    "    top_logprobs = [tuple[1] for tuple in sorted_token_probs]\n",
    "    for jj in range(len(top_tokens)):\n",
    "        print(top_tokens[jj], top_logprobs[jj])\n",
    "    \n",
    "# scoring with llama end ---------------------------------------------------\n",
    "# get prediction set\n",
    "\n",
    "    mc_smx_all = temperature_scaling(top_logprobs, temperature=5)\n",
    "\n",
    "# include all options with score >= 1-qhat\n",
    "    prediction_set = [\n",
    "          token for token_ind, token in enumerate(top_tokens)\n",
    "        #   if mc_smx_all[token_ind] >= 1 - qhat\n",
    "      ]\n",
    "\n",
    "# print\n",
    "    print('Multiple choices generated:')\n",
    "    print(demo_mc_gen_full)\n",
    "    print('\\nPrediction set:', prediction_set)\n",
    "    print('token', 'prob')\n",
    "    all_result = {}\n",
    "    token_mc_dict = {}\n",
    "    for mc in demo_mc_gen_full.split('\\n'):\n",
    "        if len(mc) < 1:\n",
    "            continue\n",
    "        if mc[0] in ['A', 'B', 'C', 'D', 'E']:\n",
    "            token_mc_dict[mc[0]] = mc[2:].strip()\n",
    "    for token_ind, token in enumerate(top_tokens):\n",
    "        print(token, mc_smx_all[token_ind])\n",
    "        all_result[token_ind+1]={\n",
    "            'action': token_mc_dict[token],\n",
    "            'confidence': mc_smx_all[token_ind]\n",
    "        }\n",
    "    \n",
    "    result['all_result'] = all_result\n",
    "    result['action'] = all_result[1]['action']\n",
    "    result['confidence'] = mc_smx_all[0]\n",
    "    return result\n",
    "\n",
    "def collect_conformal_outputs(data, force_rerun=False, num_ensemble=NUM_ENSEMBLE):\n",
    "    if 'conformal_output' in data and not force_rerun:\n",
    "        return\n",
    "    all_outputs = []\n",
    "    for i in range(num_ensemble):\n",
    "        conformal_prediction_output = generate_multiple_choice(data)\n",
    "        all_outputs.append(conformal_prediction_output)\n",
    "    print(f'scene: {data[\"scene\"]}\\ntask: {data[\"task\"]}\\nconformal_prediction_output: {conformal_prediction_output}\\n')\n",
    "    print('-'*100)\n",
    "    data['conformal_output'] = all_outputs\n",
    "\n",
    "# print(generate_conformal_prediction(scenario_data[128], num_ensemble=1, force_rerun=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 动作对齐\n",
    "action_example = '''\n",
    "\"action1:'pick up the coke', action2:'pick up the sprite',No\n",
    "action1:'Bring the Coke', action2:'I will bring you the Coke',Yes\n",
    "action1:'Retrieve the Sprite from the counter', action2:'Bring you the Sprite',Yes\n",
    "action1:'Bring the Coke', action2:'Pick the Coke',Yes\n",
    "action1:'Bring the Coke', action2:'I will retrieve the Coke from the counter and hand it to you.',Yes\n",
    "action1:'Bring you the Sprite', action2: 'Bring you a Coke',No\"\n",
    "'''\n",
    "instruction_prompt = '''\n",
    "Similar actions are actions that have the object and simliar action. \n",
    "For example, \n",
    "\"pick up the coke\" and \"bring the coke\" are similar actions. \n",
    "\"bring orange to bottled water\" and \"move orange to bottled water\" are similar actions.\n",
    "\"bring the coke\" and \"bring the sprite\" are not similar actions. \n",
    "\n",
    "If two actions want to move the object to a location and the locations are same.\n",
    "Then the two actions are similar.\n",
    "For example,\n",
    "\"bring the coke to the table\" and \"pick up the coke to the table\" are similar actions.\n",
    "\"bring the coke to the landfill bin\" and \"pick up the coke to the recycling bin\" are not similar actions.\n",
    "\"bring the coke to the landfill bin\" and \"pick up the coke\" are not similar actions.\n",
    "\n",
    "If two actions want to move same object to you or your hand, then the two actions are similar.\n",
    "For example,\n",
    "\"bring the coke to you\" and \"pick up the coke to your hand\" are similar actions.\n",
    "\"bring the coke to you\" and \"pick up the coke to here\" are similar actions.\n",
    "\"bring the coke to you\" and \"pick up the sprite to here\" are not similar actions.\n",
    "'''\n",
    "\n",
    "def check_if_action_same(action1, action2):\n",
    "    def format(action):\n",
    "        action = action.lower()\n",
    "        action = action.replace('the', '')\n",
    "        action = action.replace('a', '')\n",
    "        action = action.replace('an', '')\n",
    "        action = action.replace('to you', '')\n",
    "        action = action.replace('to here', '')\n",
    "        action = action.replace('to user', '')\n",
    "        action = action.replace('bring', 'pick up')\n",
    "        action = action.replace('pick-up', 'pick up')\n",
    "        action = action.replace('move', 'pick up')\n",
    "        action = action.replace('put', 'pick up')\n",
    "        action = action.replace('I will ', '')\n",
    "        delete_words = ['bag of', 'box of', 'bottle of']\n",
    "        for word in delete_words:\n",
    "            action = action.replace(word, '')\n",
    "        while '  ' in action:\n",
    "            action = action.replace('  ', ' ')\n",
    "        action = action.strip()\n",
    "        return action\n",
    "    return format(action1) == format(action2)\n",
    "\n",
    "def simple_action_classification(actions):\n",
    "    small_actions = actions.copy()\n",
    "    small_classes = []\n",
    "    while len(small_actions) > 0:\n",
    "        action2 = small_actions.pop(0)\n",
    "        small_class = [action2]\n",
    "        for i in range(len(small_actions)):\n",
    "            if check_if_action_same(action2, small_actions[i]):\n",
    "                small_class.append(small_actions[i])\n",
    "        for ac in small_class[1:]:\n",
    "            small_actions.remove(ac)\n",
    "        small_classes.append(small_class)\n",
    "    return small_classes\n",
    "\n",
    "\n",
    "def classify_similar_actions(all_outputs):\n",
    "    actions = list(all_outputs)\n",
    "    # print(actions)\n",
    "    action_classes = []\n",
    "    while len(actions) > 0:\n",
    "        action1 = actions.pop(0)\n",
    "        print(f'l{len(actions)}',end=' ')\n",
    "        action_class = [action1]\n",
    "        # 提前采用简单方法进行分类\n",
    "        small_classes = simple_action_classification(actions)\n",
    "\n",
    "        for small_class in small_classes:\n",
    "            act = small_class[0]\n",
    "            if check_if_action_same(action1, act):\n",
    "                response = \"yes\"\n",
    "            else:\n",
    "                messages = [\n",
    "                    {\"role\": \"system\", \"content\": \"you are a artificial intelligence assistant, you need to answer the following question\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"you need to answer if the following two action descriptions are similar. {instruction_prompt}\"},\n",
    "                    {\"role\": \"user\", \"content\": \"Are the following two action descriptions similar? action1:'{}' action2:'{}'\".format(act, action1)},\n",
    "                    {\"role\": \"user\", \"content\": \"reply with Yes or No ONLY. do not give any explanation.\"},\n",
    "                ]\n",
    "                response, messages = chat(messages, max_length=1000, do_sample=False)\n",
    "                # print(response)\n",
    "            if 'yes' in response.lower():\n",
    "                action_class.extend(small_class)\n",
    "        for action in action_class[1:]:\n",
    "            actions.remove(action)\n",
    "        action_classes.append(action_class)\n",
    "\n",
    "\n",
    "    #     for i in range(len(actions)):\n",
    "    #         print('|', end='')\n",
    "    #         if check_if_action_same(actions[i],action1):\n",
    "    #             response = \"yes\"\n",
    "    #         else:\n",
    "    #             messages = [\n",
    "    #                 {\"role\": \"system\", \"content\": \"you are a artificial intelligence assistant, you need to answer the following question\"},\n",
    "    #                 # {\"role\": \"user\", \"content\": \"you need to answer if the following two action descriptions are similar. Some examples are as follows:{}\".format(action_example)},\n",
    "    #                 {\"role\": \"user\", \"content\": f\"you need to answer if the following two action descriptions are similar. {instruction_prompt}\"},\n",
    "    #                 {\"role\": \"user\", \"content\": \"Are the following two action descriptions similar? action1:'{}' action2:'{}'\".format(actions[i], action1)},\n",
    "    #                 {\"role\": \"user\", \"content\": \"reply with Yes or No\"},\n",
    "    #             ]\n",
    "    #             response, messages = chat(messages, max_length=1000, do_sample=False)\n",
    "    #         if 'yes' in response.lower():\n",
    "    #             action_class.append(actions[i])\n",
    "    #     action_classes.append(action_class)\n",
    "    #     for action in action_class[1:]:\n",
    "    #         actions.remove(action)\n",
    "    # for action_class in action_classes:\n",
    "    #     print(action_class)\n",
    "    return action_classes\n",
    "# a = ['pick-up Pepsi to user', 'pick-up Coke to you']\n",
    "# classify_similar_actions(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 动作原子化\n",
    "atomic_prompt = '''\n",
    "NOTE:\"You need to reply with the following format:\n",
    "\"action:[the action will be done, with a single action, not a sentence, SHOULD be the action in above content]\n",
    "object:[the object that the action will be done on, with a single object, not a sentence, should be the object in above content, should NOT have verbs in the object]\n",
    "from location:[the location where the action will be done, with a single location, not a sentence, should be in above content, say NULL if no from location]\n",
    "to location:[the location where the object will be moved to, with a single location, not a sentence, should be in above content]\"\n",
    "you can reply with \"NULL\" for the space you are not sure.\n",
    "You need to reply with the words appeared in the above sentence.\"\n",
    "'''\n",
    "def make_action_atomic(action, scene_objects):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"you are a artificial intelligence assistant, you need to answer the following question\"},\n",
    "        {\"role\": \"user\", \"content\": \"read the sentence:'{}', what is the action it done?\".format(action)},\n",
    "        {\"role\": \"user\", \"content\": atomic_prompt},\n",
    "    ]\n",
    "    response, messages = chat(messages, max_length=1000, do_sample=False)\n",
    "    # print(response)\n",
    "    action_data = {\n",
    "        'action': response.split('action:')[1].split('\\n')[0].strip().lower(),\n",
    "        'object': response.split('object:')[1].split('from location:')[0].strip().lower(),\n",
    "        'from_location': response.split('from location:')[1].split('to location:')[0].strip().lower(),\n",
    "        'to_location': response.split('to location:')[1].strip().lower(),\n",
    "    }\n",
    "    for obj in scene_objects:\n",
    "        if obj.lower() in action_data['object']:\n",
    "            action_data['object'] = obj.strip()\n",
    "            break\n",
    "\n",
    "    def location_format(location):\n",
    "        delete_words = ['next to ', 'next ', 'besides ', 'beside ','the ']\n",
    "        for word in delete_words:\n",
    "            location = location.replace(word, '')\n",
    "        return location\n",
    "    action_data['from_location'] = location_format(action_data['from_location'])\n",
    "    action_data['to_location'] = location_format(action_data['to_location'])\n",
    "    should_not_have_words = ['user', 'you', 'here']\n",
    "    # if any in action_data['to_location']:\n",
    "    if any([word in action_data['to_location'] for word in should_not_have_words]):\n",
    "        action_data['to_location'] = 'null'\n",
    "    action_data['reconstructed_action'] = action_data['action'] + ' ' + action_data['object']\n",
    "    if action_data['to_location'] and 'null' not in action_data['to_location'].lower():\n",
    "        action_data['reconstructed_action'] += ' to ' + action_data['to_location']\n",
    "    return action_data\n",
    "\n",
    "# actions = ['Open bottom drawer', 'Dispose of the orange soda in the landfill bin.', 'Open the landfill bin and dispose of the orange soda.', 'Throw orange soda into recycling bin', 'Throw the orange soda away in the landfill bin.', 'Open top drawer', \"I will dispose of the orange soda in the landfill bin, considering the contents, and then place the container in the recycling bin if it's recyclable.\", 'I will dispose of the orange soda in the recycling bin.', 'Dispose of the orange soda in the recycling bin.', 'I will throw the orange soda into the landfill bin.', 'I will throw the orange soda into the landfill bin', 'Throw orange soda into compost bin', 'Throw orange soda into landfill bin', 'Throw the orange soda in the landfill bin.','Bring the Coke', 'Bring the Coke.', 'I will pick up the Coke.', 'I will bring the Coke.', 'Pick up the Coke', 'Pick up the Coke.', 'Bring the bottled unsweetened tea', 'Bring the Sprite', 'I will bring the Coke or the Sprite', 'Open the top drawer.', 'Pick up the Coke from the counter.']\n",
    "# atomic_actions = []\n",
    "# for action in actions:\n",
    "#     print(action)\n",
    "#     atomic_action_data = make_action_atomic(action)\n",
    "#     atomic_actions.append(atomic_action_data)\n",
    "#     for k,v in atomic_action_data.items():\n",
    "#         print(f'{k}: {v}')\n",
    "#     print('*'*100)\n",
    "\n",
    "# reconstructed_actions = [data['reconstructed_action'] for data in atomic_actions]\n",
    "# action_classes = classify_similar_actions(reconstructed_actions)\n",
    "# # 展示分类结果\n",
    "# for action_class in action_classes:\n",
    "#     print('-'*100)\n",
    "#     print(action_class)\n",
    "\n",
    "# action = 'pick-up rice chips to landfill bin'\n",
    "# make_action_atomic(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 动作对齐\n",
    "def action_reformat(action):\n",
    "    return action.replace('.', '')\n",
    "\n",
    "def process_action_outputs(data, force_rerun=False):\n",
    "    get_atomic_data(data, force_rerun)\n",
    "    get_answer_dict(data, force_rerun)\n",
    "\n",
    "def get_atomic_data(data, force_rerun=False):\n",
    "    all_actions = set()\n",
    "    for k,v in data.items():\n",
    "        if 'new_' in k:\n",
    "            continue\n",
    "        if k == 'top_k_output' or k == 'conformal_prediction_output':\n",
    "            for output_dict in v:\n",
    "                aciont1 = output_dict['action']\n",
    "                all_actions.add(action_reformat(aciont1))\n",
    "                for k2, v2 in output_dict['all_result'].items():\n",
    "                    action2 = v2['action']\n",
    "                    all_actions.add(action_reformat(action2))\n",
    "        elif 'output' in k:\n",
    "            for output_dict in v:\n",
    "                all_actions.add(action_reformat(output_dict['action']))\n",
    "    print(len(all_actions),all_actions)\n",
    "    atomic_dict = {}\n",
    "    if 'atomic_dict' in data and not force_rerun:\n",
    "        atomic_dict = data['atomic_dict']\n",
    "    \n",
    "    for action in all_actions:\n",
    "        if action in atomic_dict and not force_rerun:\n",
    "            continue\n",
    "        scene_objects = data['scene_objects'].split(',')\n",
    "        atomic_action_data = make_action_atomic(action, scene_objects)\n",
    "        print(atomic_action_data)\n",
    "        if atomic_action_data['object'].lower() not in data['scene_objects'].lower() and atomic_action_data['object'].lower() not in data['scene'].lower():\n",
    "            print(f'object: {atomic_action_data[\"object\"]} not in scene_objects: {data[\"scene_objects\"]}')\n",
    "            for k in atomic_action_data:\n",
    "                atomic_action_data[k] = 'NULL'\n",
    "        atomic_dict[action] = atomic_action_data\n",
    "        print('*', end='')\n",
    "    print('*'*100)\n",
    "    data['atomic_dict'] = atomic_dict\n",
    "    \n",
    "def get_answer_dict(data, force_rerun=False):\n",
    "    answer_dict = {}\n",
    "    atomic_dict = data['atomic_dict']\n",
    "    classed_atomic_dict = {}\n",
    "    for k,v in atomic_dict.items():\n",
    "        obj = v['object'].lower().strip()\n",
    "        obj = refomat_obj(obj)\n",
    "        if obj not in classed_atomic_dict:\n",
    "            classed_atomic_dict[obj] = []\n",
    "        classed_atomic_dict[obj].append(v['reconstructed_action'])\n",
    "    # for k,v in classed_atomic_dict.items():\n",
    "    #     print('*'*100)\n",
    "    #     print(k)\n",
    "    #     for action in v:\n",
    "    #         print(action)\n",
    "    # print('*'*100)\n",
    "    all_action_classes = []\n",
    "    for k,v in classed_atomic_dict.items():\n",
    "        print(len(v), end='')\n",
    "        action_classes = classify_similar_actions(v)\n",
    "        all_action_classes.extend(action_classes)\n",
    "        print('-', end='')\n",
    "    action_classes = all_action_classes\n",
    "    for index, action_class in enumerate(action_classes): \n",
    "        print('-'*20+'action_class'+'-'*20)\n",
    "        for action in action_class:\n",
    "            print(action)\n",
    "            for k,v in atomic_dict.items():\n",
    "                if v['reconstructed_action'] == action:\n",
    "                    # print(k)\n",
    "                    if index not in answer_dict:\n",
    "                        answer_dict[index] = {'reconstructed_action':action}\n",
    "                        answer_dict[index].update(v)               \n",
    "                    v['answer'] = index\n",
    "    data['answer_dict'] = answer_dict\n",
    "    print('*'*100)\n",
    "\n",
    "def refomat_obj(obj):\n",
    "    delete_words = ['bag of', 'box of', 'bottle of', 'a', 'an', 'the'] \n",
    "    for word in delete_words:\n",
    "        obj = obj.replace(word, '')\n",
    "    while '  ' in obj:\n",
    "        obj = obj.replace('  ', ' ')\n",
    "    return obj\n",
    "\n",
    "# import pickle\n",
    "# i = 102\n",
    "# pickle_file_path = \"cache/data{}.pkl\".format(i)\n",
    "# with open(pickle_file_path, \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "# get_atomic_data(data, force_rerun=True)\n",
    "# get_answer_dict(data, force_rerun=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正确答案检测\n",
    "def find_matching_answer(data):\n",
    "    user_intent_location = data['user_intent_location']\n",
    "    user_intent_object = data['user_intent_object']\n",
    "    answer_dict = data['answer_dict']\n",
    "    print(f'user_intent_location: {user_intent_location}')\n",
    "    print(f'user_intent_object: {user_intent_object}')\n",
    "    print(f'answer_dict: {answer_dict}')\n",
    "    data['right_answer'] = -1\n",
    "    to_user = False\n",
    "    if user_intent_location == 'pick-up':\n",
    "        user_intent_location = ''\n",
    "        to_user = True\n",
    "    for answer_index, answer_data in answer_dict.items():\n",
    "        if not user_intent_location.lower() in answer_data['to_location'].lower():\n",
    "            continue\n",
    "        if to_user:\n",
    "            should_have_elements = ['NULL','user','you','here']\n",
    "            if not any([element.lower() in answer_data['to_location'].lower() for element in should_have_elements]):\n",
    "                continue\n",
    "            # print(f'location: {answer_data[\"to_location\"]}')\n",
    "        for u_obj in user_intent_object.split(','):\n",
    "            if 'with' in u_obj:\n",
    "                u_obj = u_obj.split('with')[0].strip()\n",
    "            if u_obj.lower() in answer_data['object'].lower():\n",
    "                print(f'right answer: {answer_data[\"reconstructed_action\"]}')\n",
    "                data['right_answer'] = answer_index\n",
    "\n",
    "# import pickle\n",
    "# i = 216\n",
    "# pickle_file_path = \"cache/data{}.pkl\".format(i)\n",
    "# with open(pickle_file_path, \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "# find_matching_answer(data)\n",
    "# data['answer_dict']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理 将动作对齐到answer index\n",
    "def align_atomic_actions(data):\n",
    "    print('_'*20, '开始处理新情景', '_'*20)\n",
    "    ori_data = data\n",
    "    data = copy.deepcopy(data)\n",
    "    for k,v in data.items():\n",
    "        if k == 'top_k_output' or k == 'conformal_prediction_output':\n",
    "            for output_dict in v:\n",
    "                top_k_result = output_dict['all_result']\n",
    "                for k2, v2 in top_k_result.items():\n",
    "                    action = v2['action']\n",
    "                    for k3, v3 in data['atomic_dict'].items():\n",
    "                        if k3 == action_reformat(action):\n",
    "                            v2['action'] = v3['answer']\n",
    "        if 'output' in k and 'new_' not in k:\n",
    "            for output_dict in v:\n",
    "                action = output_dict['action']\n",
    "                for k2, v2 in data['atomic_dict'].items():\n",
    "                    if k2 == action_reformat(action):\n",
    "                        output_dict['action'] = v2['answer']\n",
    "            ori_data['new_'+k] = v\n",
    "            print(v)\n",
    "\n",
    "# for data in scenario_data:\n",
    "#     align_atomic_actions(data)\n",
    "#     print('_'*20, '处理完成', '_'*20)\n",
    "#     print(scenario_data)\n",
    "# 未聚合情况下各方案正确答案提取\n",
    "def evaluate_output_confidence1(data):\n",
    "    data['result'] = {}\n",
    "    for k,v in data.items():\n",
    "        if 'output' in k and 'new_' in k:\n",
    "            experiment_name = k.split('_')[1]\n",
    "            data['result'][experiment_name] = {\n",
    "                    'answer': data[k][0]['action'],\n",
    "                    'confidence': data[k][0]['confidence'],\n",
    "                    'right': data['right_answer'] == data[k][0]['action']\n",
    "                }\n",
    "            print(f'{experiment_name}: {data[k][0][\"action\"]}, {data[k][0][\"confidence\"]}, {data[\"right_answer\"] == data[k][0][\"action\"]}')\n",
    "\n",
    "# i = 299\n",
    "# pickle_file_path = \"cache/data{}.pkl\".format(i)\n",
    "# with open(pickle_file_path, \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "# align_atomic_actions(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_process_method(data):\n",
    "    # 收集不同测试方法数据\n",
    "    print('collect_vanilla_outputs'+'-'*100)\n",
    "    collect_vanilla_outputs(prompt_vanilla, data)\n",
    "    print('collect_cot_output'+'-'*100)\n",
    "    collect_cot_output(data)\n",
    "    print('collect_self_prob_outputs'+'-'*100)\n",
    "    collect_self_prob_outputs(data)\n",
    "    print('collect_multi_step_output'+'-'*100)\n",
    "    collect_multi_step_output(data)\n",
    "    print('collect_top_k_outputs'+'-'*100)\n",
    "    collect_top_k_outputs(data)\n",
    "    print('collect_conformal_outputs'+'-'*100)\n",
    "    collect_conformal_outputs(data)\n",
    "\n",
    "\n",
    "    # 对齐动作（重复归一）\n",
    "    print('process_action_outputs'+'-'*100)\n",
    "    process_action_outputs(data)\n",
    "    # 找到正确答案\n",
    "    print('find_matching_answer'+'-'*100)\n",
    "    find_matching_answer(data)\n",
    "    #动作更新为answer index\n",
    "    print('align_atomic_actions'+'-'*100)\n",
    "    align_atomic_actions(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5932fc10c92645669fb69559e5b82db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 开始处理新情景[0] --------------------\n",
      "collect_vanilla_outputs----------------------------------------------------------------------------------------------------\n",
      "collect_cot_output----------------------------------------------------------------------------------------------------\n",
      "collect_self_prob_outputs----------------------------------------------------------------------------------------------------\n",
      "collect_multi_step_output----------------------------------------------------------------------------------------------------\n",
      "collect_top_k_outputs----------------------------------------------------------------------------------------------------\n",
      "collect_conformal_outputs----------------------------------------------------------------------------------------------------\n",
      "process_action_outputs----------------------------------------------------------------------------------------------------\n",
      "10 {'pick-up Coke to compost bin', 'pick-up, Coke', 'pick-up Coke to bottom drawer', 'pick-up Sprite', 'pick-up Coke to landfill bin', 'I will pick-up the Coke', 'pick-up Coke to top drawer', 'pick-up Coke to recycling bin', 'pick up the sprite', 'pick-up Coke'}\n",
      "****************************************************************************************************\n",
      "8l7 l3 l1 l0 -2l1 ---------------------action_class--------------------\n",
      "pick-up Coke to compost bin\n",
      "pick-up Coke\n",
      "pick-up Coke\n",
      "pick-up Coke\n",
      "--------------------action_class--------------------\n",
      "pick-up Coke to drawer\n",
      "pick-up Coke to drawer\n",
      "--------------------action_class--------------------\n",
      "pick-up Coke to landfill bin\n",
      "--------------------action_class--------------------\n",
      "pick-up Coke to recycling bin\n",
      "--------------------action_class--------------------\n",
      "pick-up sprite\n",
      "pick up sprite\n",
      "****************************************************************************************************\n",
      "find_matching_answer----------------------------------------------------------------------------------------------------\n",
      "user_intent_location: pick-up\n",
      "user_intent_object: Coke, bottled unsweetened tea, Sprite\n",
      "answer_dict: {0: {'reconstructed_action': 'pick-up Coke to compost bin', 'action': 'pick-up', 'object': 'Coke', 'from_location': 'null', 'to_location': 'compost bin', 'answer': 0}, 1: {'reconstructed_action': 'pick-up Coke to drawer', 'action': 'pick-up', 'object': 'Coke', 'from_location': 'null', 'to_location': 'drawer', 'answer': 1}, 2: {'reconstructed_action': 'pick-up Coke to landfill bin', 'action': 'pick-up', 'object': 'Coke', 'from_location': 'null', 'to_location': 'landfill bin', 'answer': 2}, 3: {'reconstructed_action': 'pick-up Coke to recycling bin', 'action': 'pick-up', 'object': 'Coke', 'from_location': 'null', 'to_location': 'recycling bin', 'answer': 3}, 4: {'reconstructed_action': 'pick-up sprite', 'action': 'pick-up', 'object': 'sprite', 'from_location': 'null', 'to_location': 'null', 'answer': 4}}\n",
      "align_atomic_actions----------------------------------------------------------------------------------------------------\n",
      "____________________ 开始处理新情景 ____________________\n",
      "[{'action': 4, 'confidence': 1.0}]\n",
      "[{'action': 0, 'confidence': 1.0}]\n",
      "[{'action': 0, 'confidence': 1.0}]\n",
      "[{'action': 0, 'confidence': 0.0}]\n",
      "[{'action': 0, 'confidence': 1.0}]\n",
      "[{'action': 2, 'confidence': 0.0, 'all_result': {1: {'action': 2, 'confidence': 0.0}, 2: {'action': 3, 'confidence': 0.0}, 3: {'action': 0, 'confidence': 0.0}, 4: {'action': 2, 'confidence': 0.0}, 5: {'action': 0, 'confidence': 0.0}, 6: {'action': 1, 'confidence': 0.0}, 7: {'action': 1, 'confidence': 0.0}, 8: {'action': 2, 'confidence': 0.0}, 9: {'action': 3, 'confidence': 0.0}, 10: {'action': 0, 'confidence': 0.0}, 11: {'action': 2, 'confidence': 0.0}, 12: {'action': 0, 'confidence': 0.0}, 13: {'action': 1, 'confidence': 0.0}, 14: {'action': 1, 'confidence': 0.0}, 15: {'action': 2, 'confidence': 0.0}, 16: {'action': 3, 'confidence': 0.0}, 17: {'action': 0, 'confidence': 0.0}, 18: {'action': 2, 'confidence': 0.0}, 19: {'action': 0, 'confidence': 0.0}, 20: {'action': 1, 'confidence': 0.0}, 21: {'action': 1, 'confidence': 0.0}, 22: {'action': 0, 'confidence': 0.0}, 23: {'action': 2, 'confidence': 0.0}, 24: {'action': 3, 'confidence': 0.0}, 25: {'action': 0, 'confidence': 0.0}, 26: {'action': 2, 'confidence': 0.0}, 27: {'action': 0, 'confidence': 0.0}, 28: {'action': 1, 'confidence': 0.0}, 29: {'action': 1, 'confidence': 0.0}, 30: {'action': 2, 'confidence': 0.0}, 31: {'action': 3, 'confidence': 0.0}, 32: {'action': 0, 'confidence': 0.0}, 33: {'action': 2, 'confidence': 0.0}, 34: {'action': 0, 'confidence': 0.0}, 35: {'action': 1, 'confidence': 0.0}, 36: {'action': 1, 'confidence': 0.0}, 37: {'action': 0, 'confidence': 0.0}, 38: {'action': 2, 'confidence': 0.0}, 39: {'action': 3, 'confidence': 0.0}, 40: {'action': 0, 'confidence': 0.0}, 41: {'action': 2, 'confidence': 0.0}, 42: {'action': 0, 'confidence': 0.0}, 43: {'action': 1, 'confidence': 0.0}, 44: {'action': 1, 'confidence': 0.0}, 45: {'action': 0, 'confidence': 0.0}, 46: {'action': 2, 'confidence': 0.0}, 47: {'action': 3, 'confidence': 0.0}, 48: {'action': 0, 'confidence': 0.0}, 49: {'action': 2, 'confidence': 0.0}, 50: {'action': 0, 'confidence': 0.0}, 51: {'action': 1, 'confidence': 0.0}, 52: {'action': 1, 'confidence': 0.0}, 53: {'action': 0, 'confidence': 0.0}, 54: {'action': 2, 'confidence': 0.0}, 55: {'action': 3, 'confidence': 0.0}, 56: {'action': 0, 'confidence': 0.0}, 57: {'action': 2, 'confidence': 0.0}, 58: {'action': 0, 'confidence': 0.0}, 59: {'action': 1, 'confidence': 0.0}, 60: {'action': 1, 'confidence': 0.0}, 61: {'action': 0, 'confidence': 0.0}, 62: {'action': 2, 'confidence': 0.0}, 63: {'action': 3, 'confidence': 0.0}, 64: {'action': 0, 'confidence': 0.0}, 65: {'action': 2, 'confidence': 0.0}}}]\n",
      "[{'all_result': {1: {'action': 'pick up the sprite', 'confidence': np.float64(0.22700450950435774)}, 2: {'action': 'pick up the coke', 'confidence': np.float64(0.21458799917120278)}, 3: {'action': 'pick up the bottled water', 'confidence': np.float64(0.2127517848375339)}, 4: {'action': 'an option not listed here', 'confidence': np.float64(0.18878238142355436)}, 5: {'action': 'pick up the bottled unsweetened tea', 'confidence': np.float64(0.15687332506335136)}}, 'action': 4, 'confidence': np.float64(0.22700450950435774)}]\n",
      "-------------------- 开始处理新情景[1] --------------------\n",
      "collect_vanilla_outputs----------------------------------------------------------------------------------------------------\n",
      "collect_cot_output----------------------------------------------------------------------------------------------------\n",
      "collect_self_prob_outputs----------------------------------------------------------------------------------------------------\n",
      "collect_multi_step_output----------------------------------------------------------------------------------------------------\n",
      "collect_top_k_outputs----------------------------------------------------------------------------------------------------\n",
      "collect_conformal_outputs----------------------------------------------------------------------------------------------------\n",
      "process_action_outputs----------------------------------------------------------------------------------------------------\n",
      "10 {'pick up the pepsi', 'Pick-up RedBull', 'open top drawer', 'I will pick-up the RedBull', 'move Coke to you', 'pick-up', 'move Pepsi to you', 'open bottom drawer', 'pick-up RedBull', 'move RedBull to you'}\n",
      "****************************************************************************************************\n",
      "2l1 -4l3 -3l2 -1l0 ---------------------action_class--------------------\n",
      "pick up Pepsi\n",
      "move Pepsi\n",
      "--------------------action_class--------------------\n",
      "pick-up redbull\n",
      "pick-up redbull\n",
      "pick-up redbull\n",
      "move redbull\n",
      "--------------------action_class--------------------\n",
      "NULL\n",
      "NULL\n",
      "NULL\n",
      "--------------------action_class--------------------\n",
      "move coke\n",
      "****************************************************************************************************\n",
      "find_matching_answer----------------------------------------------------------------------------------------------------\n",
      "user_intent_location: pick-up\n",
      "user_intent_object: RedBull\n",
      "answer_dict: {0: {'reconstructed_action': 'pick up Pepsi', 'action': 'pick up', 'object': 'Pepsi', 'from_location': 'null', 'to_location': 'null', 'answer': 0}, 1: {'reconstructed_action': 'pick-up redbull', 'action': 'pick-up', 'object': 'redbull', 'from_location': 'null', 'to_location': 'null', 'answer': 1}, 2: {'reconstructed_action': 'NULL', 'action': 'NULL', 'object': 'NULL', 'from_location': 'NULL', 'to_location': 'NULL', 'answer': 2}, 3: {'reconstructed_action': 'move coke', 'action': 'move', 'object': 'coke', 'from_location': 'null', 'to_location': 'null', 'answer': 3}}\n",
      "right answer: pick-up redbull\n",
      "align_atomic_actions----------------------------------------------------------------------------------------------------\n",
      "____________________ 开始处理新情景 ____________________\n",
      "[{'action': 1, 'confidence': 1.0}]\n",
      "[{'action': 1, 'confidence': 1.0}]\n",
      "[{'action': 1, 'confidence': 1.0}]\n",
      "[{'action': 1, 'confidence': 0.0}]\n",
      "[{'action': 2, 'confidence': 0.8}]\n",
      "[{'action': 1, 'confidence': 0.8, 'all_result': {1: {'action': 1, 'confidence': 0.8}, 2: {'action': 1, 'confidence': 0.15}, 3: {'action': 2, 'confidence': 0.05}, 4: {'action': 2, 'confidence': 0.0}, 5: {'action': 3, 'confidence': 0.0}, 6: {'action': 0, 'confidence': 0.0}}}]\n",
      "[{'all_result': {1: {'action': 'pick up the pepsi', 'confidence': np.float64(0.21796602692075678)}, 2: {'action': 'an option not listed here', 'confidence': np.float64(0.21291684934540336)}, 3: {'action': 'pick up the redbull', 'confidence': np.float64(0.2044404450523976)}, 4: {'action': 'pick up the redbull and put it in the top drawer', 'confidence': np.float64(0.18397649128181354)}, 5: {'action': 'pick up the coke', 'confidence': np.float64(0.18070018739962854)}}, 'action': 0, 'confidence': np.float64(0.21796602692075678)}]\n",
      "-------------------- 开始处理新情景[2] --------------------\n",
      "collect_vanilla_outputs----------------------------------------------------------------------------------------------------\n",
      "collect_cot_output----------------------------------------------------------------------------------------------------\n",
      "collect_self_prob_outputs----------------------------------------------------------------------------------------------------\n",
      "collect_multi_step_output----------------------------------------------------------------------------------------------------\n",
      "collect_top_k_outputs----------------------------------------------------------------------------------------------------\n",
      "collect_conformal_outputs----------------------------------------------------------------------------------------------------\n",
      "process_action_outputs----------------------------------------------------------------------------------------------------\n",
      "9 {'open top drawer', 'I will open the landfill bin', 'pick up the apple and put it in the compost bin', 'Open the top drawer', 'move orange soda to landfill bin', 'open bottom drawer', 'Pick-up the orange soda', 'pick-up orange soda', 'pick-up orange'}\n",
      "****************************************************************************************************\n",
      "4l3 -1l0 -3l2 l1 -1l0 ---------------------action_class--------------------\n",
      "NULL\n",
      "NULL\n",
      "NULL\n",
      "NULL\n",
      "--------------------action_class--------------------\n",
      "pick up apple to compost bin\n",
      "--------------------action_class--------------------\n",
      "move orange soda to landfill bin\n",
      "--------------------action_class--------------------\n",
      "pick-up orange soda\n",
      "pick-up orange soda\n",
      "--------------------action_class--------------------\n",
      "pick orange\n",
      "****************************************************************************************************\n",
      "find_matching_answer----------------------------------------------------------------------------------------------------\n",
      "user_intent_location: recycling\n",
      "user_intent_object: orange soda\n",
      "answer_dict: {0: {'reconstructed_action': 'NULL', 'action': 'NULL', 'object': 'NULL', 'from_location': 'NULL', 'to_location': 'NULL', 'answer': 0}, 1: {'reconstructed_action': 'pick up apple to compost bin', 'action': 'pick up', 'object': 'apple', 'from_location': 'null', 'to_location': 'compost bin', 'answer': 1}, 2: {'reconstructed_action': 'move orange soda to landfill bin', 'action': 'move', 'object': 'orange soda', 'from_location': 'null', 'to_location': 'landfill bin', 'answer': 2}, 3: {'reconstructed_action': 'pick-up orange soda', 'action': 'pick-up', 'object': 'orange soda', 'from_location': 'null', 'to_location': 'null', 'answer': 3}, 4: {'reconstructed_action': 'pick orange', 'action': 'pick', 'object': 'orange', 'from_location': 'null', 'to_location': 'null', 'answer': 4}}\n",
      "align_atomic_actions----------------------------------------------------------------------------------------------------\n",
      "____________________ 开始处理新情景 ____________________\n",
      "[{'action': 3, 'confidence': 1.0}]\n",
      "[{'action': 3, 'confidence': 0.9}]\n",
      "[{'action': 0, 'confidence': 1.0}]\n",
      "[{'action': 0, 'confidence': 0.0}]\n",
      "[{'action': 0, 'confidence': 0.67032}]\n",
      "[{'action': 3, 'confidence': 0.8, 'all_result': {1: {'action': 3, 'confidence': 0.8}, 2: {'action': 0, 'confidence': 0.15}, 3: {'action': 2, 'confidence': 0.05}, 4: {'action': 4, 'confidence': 0.0}, 5: {'action': 0, 'confidence': 0.0}}}]\n",
      "[{'all_result': {1: {'action': 'pick up the apple and put it in the compost bin', 'confidence': np.float64(0.22512486181792027)}, 2: {'action': 'an option not listed here', 'confidence': np.float64(0.21802809697583497)}, 3: {'action': 'pick up the orange soda and put it in the recycling bin', 'confidence': np.float64(0.20658618574148588)}, 4: {'action': 'pick up the orange soda and put it in the landfill bin', 'confidence': np.float64(0.17684063145013706)}, 5: {'action': 'pick up the orange and put it in the compost bin', 'confidence': np.float64(0.17342022401462182)}}, 'action': 1, 'confidence': np.float64(0.22512486181792027)}]\n",
      "-------------------- 开始处理新情景[3] --------------------\n",
      "collect_vanilla_outputs----------------------------------------------------------------------------------------------------\n",
      "collect_cot_output----------------------------------------------------------------------------------------------------\n",
      "collect_self_prob_outputs----------------------------------------------------------------------------------------------------\n",
      "collect_multi_step_output----------------------------------------------------------------------------------------------------\n",
      "collect_top_k_outputs----------------------------------------------------------------------------------------------------\n",
      "collect_conformal_outputs----------------------------------------------------------------------------------------------------\n",
      "process_action_outputs----------------------------------------------------------------------------------------------------\n",
      "6 {'Open', 'I will open the bottom drawer', 'open the bottom drawer and put the coke in it', 'move Coke', 'open bottom drawer', 'pick-up Coke'}\n",
      "****************************************************************************************************\n",
      "3l2 -3l2 l1 ---------------------action_class--------------------\n",
      "NULL\n",
      "NULL\n",
      "NULL\n",
      "--------------------action_class--------------------\n",
      "put coke to drawer\n",
      "--------------------action_class--------------------\n",
      "move coke\n",
      "pick-up coke\n",
      "****************************************************************************************************\n",
      "find_matching_answer----------------------------------------------------------------------------------------------------\n",
      "user_intent_location: bottom drawer\n",
      "user_intent_object: Coke\n",
      "answer_dict: {0: {'reconstructed_action': 'NULL', 'action': 'NULL', 'object': 'NULL', 'from_location': 'NULL', 'to_location': 'NULL', 'answer': 0}, 1: {'reconstructed_action': 'put coke to drawer', 'action': 'put', 'object': 'coke', 'from_location': 'null', 'to_location': 'drawer', 'answer': 1}, 2: {'reconstructed_action': 'move coke', 'action': 'move', 'object': 'coke', 'from_location': 'null', 'to_location': 'null', 'answer': 2}}\n",
      "align_atomic_actions----------------------------------------------------------------------------------------------------\n",
      "____________________ 开始处理新情景 ____________________\n",
      "[{'action': 0, 'confidence': 1.0}]\n",
      "[{'action': 2, 'confidence': 1.0}]\n",
      "[{'action': 0, 'confidence': 1.0}]\n",
      "[{'action': 0, 'confidence': 0.0}]\n",
      "[{'action': 0, 'confidence': 1.0}]\n",
      "[{'action': 2, 'confidence': 0.9, 'all_result': {1: {'action': 2, 'confidence': 0.9}, 2: {'action': 0, 'confidence': 0.09}, 3: {'action': 2, 'confidence': 0.01}}}]\n",
      "[{'all_result': {1: {'action': 'open the bottom drawer and put the coke in it', 'confidence': np.float64(0.25796757837208834)}, 2: {'action': 'an option not listed here', 'confidence': np.float64(0.20279769622203742)}, 3: {'action': 'open the top drawer and put the coke in it', 'confidence': np.float64(0.1993418941897686)}, 4: {'action': 'open the top drawer and put the energy bar in it', 'confidence': np.float64(0.1775755961054914)}, 5: {'action': 'open the bottom drawer and put the energy bar in it', 'confidence': np.float64(0.16231723511061433)}}, 'action': 1, 'confidence': np.float64(0.25796757837208834)}]\n",
      "-------------------- 开始处理新情景[4] --------------------\n",
      "collect_vanilla_outputs----------------------------------------------------------------------------------------------------\n",
      "collect_cot_output----------------------------------------------------------------------------------------------------\n",
      "collect_self_prob_outputs----------------------------------------------------------------------------------------------------\n",
      "collect_multi_step_output----------------------------------------------------------------------------------------------------\n",
      "collect_top_k_outputs----------------------------------------------------------------------------------------------------\n",
      "collect_conformal_outputs----------------------------------------------------------------------------------------------------\n",
      "process_action_outputs----------------------------------------------------------------------------------------------------\n",
      "10 {'move RedBull to recycling bin', 'I will pick-up the RedBull and bring it to the landfill bin', 'open top drawer', 'pick-up the RedBull', 'pick up the redbull and put it in the recycling bin', 'Open the top drawer', 'move RedBull to compost bin', 'Pick-up the RedBull', 'move RedBull to landfill bin', 'pick-up RedBull'}\n",
      "****************************************************************************************************\n",
      "8l7 l5 l3 l0 -2l1 ---------------------action_class--------------------\n",
      "move RedBull to recycling bin\n",
      "pick up RedBull to recycling bin\n",
      "--------------------action_class--------------------\n",
      "pick-up RedBull to landfill bin\n",
      "move RedBull to landfill bin\n",
      "--------------------action_class--------------------\n",
      "pick-up RedBull\n",
      "pick-up RedBull\n",
      "pick-up RedBull\n",
      "--------------------action_class--------------------\n",
      "move RedBull to compost bin\n",
      "--------------------action_class--------------------\n",
      "NULL\n",
      "NULL\n",
      "****************************************************************************************************\n",
      "find_matching_answer----------------------------------------------------------------------------------------------------\n",
      "user_intent_location: recycling\n",
      "user_intent_object: bottled water\n",
      "answer_dict: {0: {'reconstructed_action': 'move RedBull to recycling bin', 'action': 'move', 'object': 'RedBull', 'from_location': 'null', 'to_location': 'recycling bin', 'answer': 0}, 1: {'reconstructed_action': 'pick-up RedBull to landfill bin', 'action': 'pick-up', 'object': 'RedBull', 'from_location': 'null', 'to_location': 'landfill bin', 'answer': 1}, 2: {'reconstructed_action': 'pick-up RedBull', 'action': 'pick-up', 'object': 'RedBull', 'from_location': 'null', 'to_location': 'null', 'answer': 2}, 3: {'reconstructed_action': 'move RedBull to compost bin', 'action': 'move', 'object': 'RedBull', 'from_location': 'null', 'to_location': 'compost bin', 'answer': 3}, 4: {'reconstructed_action': 'NULL', 'action': 'NULL', 'object': 'NULL', 'from_location': 'NULL', 'to_location': 'NULL', 'answer': 4}}\n",
      "align_atomic_actions----------------------------------------------------------------------------------------------------\n",
      "____________________ 开始处理新情景 ____________________\n",
      "[{'action': 2, 'confidence': 1.0}]\n",
      "[{'action': 2, 'confidence': 0.9}]\n",
      "[{'action': 1, 'confidence': 1.0}]\n",
      "[{'action': 1, 'confidence': 0.0}]\n",
      "[{'action': 4, 'confidence': 0.39535200000000004}]\n",
      "[{'action': 2, 'confidence': 0.8, 'all_result': {1: {'action': 2, 'confidence': 0.8}, 2: {'action': 1, 'confidence': 0.15}, 3: {'action': 4, 'confidence': 0.05}, 4: {'action': 0, 'confidence': 0.0}, 5: {'action': 3, 'confidence': 0.0}}}]\n",
      "[{'all_result': {1: {'action': 'pick up the redbull and put it in the recycling bin', 'confidence': np.float64(0.2228264984910935)}, 2: {'action': 'pick up the redbull and put it in the landfill bin', 'confidence': np.float64(0.21749473886739548)}, 3: {'action': 'pick up the bottled unsweetened tea and put it in the landfill bin', 'confidence': np.float64(0.2081844907061743)}, 4: {'action': 'an option not listed here', 'confidence': np.float64(0.19496102389435818)}, 5: {'action': 'pick up the bottled water and put it in the landfill bin', 'confidence': np.float64(0.15653324804097854)}}, 'action': 0, 'confidence': np.float64(0.2228264984910935)}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if TEST_FLAG:\n",
    "    scenario_data = scenario_data[:5]\n",
    "\n",
    "for data_index in tqdm.tqdm(range(len(scenario_data))):\n",
    "    data = scenario_data[data_index]\n",
    "    pickle_path = f\"./cache/data{data['index']}.pkl\"\n",
    "\n",
    "    if os.path.exists(pickle_path):\n",
    "        # # --------- 为了重新运行其中一些内容 还有force_rerun参数记得改\n",
    "        with open(pickle_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        scenario_data[data_index] = data\n",
    "        # # ---------- 结束\n",
    "        # continue\n",
    "    # error_path = f'./cache/error{data[\"index\"]}.pkl'\n",
    "    # if os.path.exists(error_path):\n",
    "    #     continue\n",
    "    print('-'*20, f'开始处理新情景[{data[\"index\"]}]', '-'*20)\n",
    "    try:\n",
    "        all_process_method(data)\n",
    "        # save data to ./cache/data[index].pkl\n",
    "        with open(f'./cache/data{data[\"index\"]}.pkl', 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "    except Exception as e:\n",
    "        # raise e\n",
    "        with open(f'./cache/error{data[\"index\"]}.pkl', 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下一步去cache_check文件运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 0,\n",
       " 'scene': 'a Coke, a bottled unsweetened tea, and a Sprite',\n",
       " 'task': 'Bring me a flavored drink.',\n",
       " 'user_intent_object': 'Coke, bottled unsweetened tea, Sprite',\n",
       " 'user_intent_location': 'pick-up',\n",
       " 'scene_objects': 'Coke, bottled unsweetened tea, Sprite',\n",
       " 'task_category': 'creative_multilabel_task',\n",
       " 'vanilla_output': [{'action': 'pick-up Sprite', 'confidence': 1.0}],\n",
       " 'cot_output': [{'action': 'pick-up Coke', 'confidence': 1.0}],\n",
       " 'self_probing_output': [{'action': 'I will pick-up the Coke.',\n",
       "   'confidence': 1.0}],\n",
       " 'self_probing_output_log': [{'action': 'I will pick-up the Coke.',\n",
       "   'confidence': 0.0}],\n",
       " 'multi_step_output': [{'action': 'pick-up, Coke', 'confidence': 1.0}],\n",
       " 'top_k_output': [{'action': 'pick-up Coke to landfill bin',\n",
       "   'confidence': 0.0,\n",
       "   'all_result': {1: {'action': 'pick-up Coke to landfill bin',\n",
       "     'confidence': 0.0},\n",
       "    2: {'action': 'pick-up Coke to recycling bin', 'confidence': 0.0},\n",
       "    3: {'action': 'pick-up Coke to compost bin', 'confidence': 0.0},\n",
       "    4: {'action': 'pick-up Coke to landfill bin', 'confidence': 0.0},\n",
       "    5: {'action': 'pick-up Coke', 'confidence': 0.0},\n",
       "    6: {'action': 'pick-up Coke to top drawer', 'confidence': 0.0},\n",
       "    7: {'action': 'pick-up Coke to bottom drawer', 'confidence': 0.0},\n",
       "    8: {'action': 'pick-up Coke to landfill bin', 'confidence': 0.0},\n",
       "    9: {'action': 'pick-up Coke to recycling bin', 'confidence': 0.0},\n",
       "    10: {'action': 'pick-up Coke to compost bin', 'confidence': 0.0},\n",
       "    11: {'action': 'pick-up Coke to landfill bin', 'confidence': 0.0},\n",
       "    12: {'action': 'pick-up Coke', 'confidence': 0.0},\n",
       "    13: {'action': 'pick-up Coke to top drawer', 'confidence': 0.0},\n",
       "    14: {'action': 'pick-up Coke to bottom drawer', 'confidence': 0.0},\n",
       "    15: {'action': 'pick-up Coke to landfill bin', 'confidence': 0.0},\n",
       "    16: {'action': 'pick-up Coke to recycling bin', 'confidence': 0.0},\n",
       "    17: {'action': 'pick-up Coke to compost bin', 'confidence': 0.0},\n",
       "    18: {'action': 'pick-up Coke to landfill bin', 'confidence': 0.0},\n",
       "    19: {'action': 'pick-up Coke', 'confidence': 0.0},\n",
       "    20: {'action': 'pick-up Coke to top drawer', 'confidence': 0.0},\n",
       "    21: {'action': 'pick-up Coke to bottom drawer', 'confidence': 0.0},\n",
       "    22: {'action': 'pick-up Coke', 'confidence': 0.0},\n",
       "    23: {'action': 'pick-up Coke to landfill bin', 'confidence': 0.0},\n",
       "    24: {'action': 'pick-up Coke to recycling bin', 'confidence': 0.0},\n",
       "    25: {'action': 'pick-up Coke to compost bin', 'confidence': 0.0},\n",
       "    26: {'action': 'pick-up Coke to landfill bin', 'confidence': 0.0},\n",
       "    27: {'action': 'pick-up Coke', 'confidence': 0.0},\n",
       "    28: {'action': 'pick-up Coke to top drawer', 'confidence': 0.0},\n",
       "    29: {'action': 'pick-up Coke to bottom drawer', 'confidence': 0.0},\n",
       "    30: {'action': 'pick-up Coke to landfill bin', 'confidence': 0.0},\n",
       "    31: {'action': 'pick-up Coke to recycling bin', 'confidence': 0.0},\n",
       "    32: {'action': 'pick-up Coke to compost bin', 'confidence': 0.0},\n",
       "    33: {'action': 'pick-up Coke to landfill bin', 'confidence': 0.0},\n",
       "    34: {'action': 'pick-up Coke', 'confidence': 0.0},\n",
       "    35: {'action': 'pick-up Coke to top drawer', 'confidence': 0.0},\n",
       "    36: {'action': 'pick-up Coke to bottom drawer', 'confidence': 0.0},\n",
       "    37: {'action': 'pick-up Coke', 'confidence': 0.0},\n",
       "    38: {'action': 'pick-up Coke to landfill bin', 'confidence': 0.0},\n",
       "    39: {'action': 'pick-up Coke to recycling bin', 'confidence': 0.0},\n",
       "    40: {'action': 'pick-up Coke to compost bin', 'confidence': 0.0},\n",
       "    41: {'action': 'pick-up Coke to landfill bin', 'confidence': 0.0},\n",
       "    42: {'action': 'pick-up Coke', 'confidence': 0.0},\n",
       "    43: {'action': 'pick-up Coke to top drawer', 'confidence': 0.0},\n",
       "    44: {'action': 'pick-up Coke to bottom drawer', 'confidence': 0.0},\n",
       "    45: {'action': 'pick-up Coke', 'confidence': 0.0},\n",
       "    46: {'action': 'pick-up Coke to landfill bin', 'confidence': 0.0},\n",
       "    47: {'action': 'pick-up Coke to recycling bin', 'confidence': 0.0},\n",
       "    48: {'action': 'pick-up Coke to compost bin', 'confidence': 0.0},\n",
       "    49: {'action': 'pick-up Coke to landfill bin', 'confidence': 0.0},\n",
       "    50: {'action': 'pick-up Coke', 'confidence': 0.0},\n",
       "    51: {'action': 'pick-up Coke to top drawer', 'confidence': 0.0},\n",
       "    52: {'action': 'pick-up Coke to bottom drawer', 'confidence': 0.0},\n",
       "    53: {'action': 'pick-up Coke', 'confidence': 0.0},\n",
       "    54: {'action': 'pick-up Coke to landfill bin', 'confidence': 0.0},\n",
       "    55: {'action': 'pick-up Coke to recycling bin', 'confidence': 0.0},\n",
       "    56: {'action': 'pick-up Coke to compost bin', 'confidence': 0.0},\n",
       "    57: {'action': 'pick-up Coke to landfill bin', 'confidence': 0.0},\n",
       "    58: {'action': 'pick-up Coke', 'confidence': 0.0},\n",
       "    59: {'action': 'pick-up Coke to top drawer', 'confidence': 0.0},\n",
       "    60: {'action': 'pick-up Coke to bottom drawer', 'confidence': 0.0},\n",
       "    61: {'action': 'pick-up Coke', 'confidence': 0.0},\n",
       "    62: {'action': 'pick-up Coke to landfill bin', 'confidence': 0.0},\n",
       "    63: {'action': 'pick-up Coke to recycling bin', 'confidence': 0.0},\n",
       "    64: {'action': 'pick-up Coke to compost bin', 'confidence': 0.0},\n",
       "    65: {'action': 'pick-up Coke to landfill bin', 'confidence': 0.0}}}],\n",
       " 'conformal_output': [{'all_result': {1: {'action': 'pick up the sprite',\n",
       "     'confidence': np.float64(0.22700450950435774)},\n",
       "    2: {'action': 'pick up the coke',\n",
       "     'confidence': np.float64(0.21458799917120278)},\n",
       "    3: {'action': 'pick up the bottled water',\n",
       "     'confidence': np.float64(0.2127517848375339)},\n",
       "    4: {'action': 'an option not listed here',\n",
       "     'confidence': np.float64(0.18878238142355436)},\n",
       "    5: {'action': 'pick up the bottled unsweetened tea',\n",
       "     'confidence': np.float64(0.15687332506335136)}},\n",
       "   'action': 'pick up the sprite',\n",
       "   'confidence': np.float64(0.22700450950435774)}],\n",
       " 'atomic_dict': {'pick-up Coke to compost bin': {'action': 'pick-up',\n",
       "   'object': 'Coke',\n",
       "   'from_location': 'null',\n",
       "   'to_location': 'compost bin',\n",
       "   'reconstructed_action': 'pick-up Coke to compost bin',\n",
       "   'answer': 0},\n",
       "  'pick-up, Coke': {'action': 'pick-up',\n",
       "   'object': 'Coke',\n",
       "   'from_location': 'null',\n",
       "   'to_location': 'null',\n",
       "   'reconstructed_action': 'pick-up Coke',\n",
       "   'answer': 0},\n",
       "  'pick-up Coke to bottom drawer': {'action': 'pick-up',\n",
       "   'object': 'Coke',\n",
       "   'from_location': 'null',\n",
       "   'to_location': 'drawer',\n",
       "   'reconstructed_action': 'pick-up Coke to drawer',\n",
       "   'answer': 1},\n",
       "  'pick-up Sprite': {'action': 'pick-up',\n",
       "   'object': 'sprite',\n",
       "   'from_location': 'null',\n",
       "   'to_location': 'null',\n",
       "   'reconstructed_action': 'pick-up sprite',\n",
       "   'answer': 4},\n",
       "  'pick-up Coke to landfill bin': {'action': 'pick-up',\n",
       "   'object': 'Coke',\n",
       "   'from_location': 'null',\n",
       "   'to_location': 'landfill bin',\n",
       "   'reconstructed_action': 'pick-up Coke to landfill bin',\n",
       "   'answer': 2},\n",
       "  'I will pick-up the Coke': {'action': 'pick-up',\n",
       "   'object': 'Coke',\n",
       "   'from_location': 'null',\n",
       "   'to_location': 'null',\n",
       "   'reconstructed_action': 'pick-up Coke',\n",
       "   'answer': 0},\n",
       "  'pick-up Coke to top drawer': {'action': 'pick-up',\n",
       "   'object': 'Coke',\n",
       "   'from_location': 'null',\n",
       "   'to_location': 'drawer',\n",
       "   'reconstructed_action': 'pick-up Coke to drawer',\n",
       "   'answer': 1},\n",
       "  'pick-up Coke to recycling bin': {'action': 'pick-up',\n",
       "   'object': 'Coke',\n",
       "   'from_location': 'null',\n",
       "   'to_location': 'recycling bin',\n",
       "   'reconstructed_action': 'pick-up Coke to recycling bin',\n",
       "   'answer': 3},\n",
       "  'pick up the sprite': {'action': 'pick up',\n",
       "   'object': 'sprite',\n",
       "   'from_location': 'null',\n",
       "   'to_location': 'null',\n",
       "   'reconstructed_action': 'pick up sprite',\n",
       "   'answer': 4},\n",
       "  'pick-up Coke': {'action': 'pick-up',\n",
       "   'object': 'Coke',\n",
       "   'from_location': 'null',\n",
       "   'to_location': 'null',\n",
       "   'reconstructed_action': 'pick-up Coke',\n",
       "   'answer': 0}},\n",
       " 'answer_dict': {0: {'reconstructed_action': 'pick-up Coke to compost bin',\n",
       "   'action': 'pick-up',\n",
       "   'object': 'Coke',\n",
       "   'from_location': 'null',\n",
       "   'to_location': 'compost bin',\n",
       "   'answer': 0},\n",
       "  1: {'reconstructed_action': 'pick-up Coke to drawer',\n",
       "   'action': 'pick-up',\n",
       "   'object': 'Coke',\n",
       "   'from_location': 'null',\n",
       "   'to_location': 'drawer',\n",
       "   'answer': 1},\n",
       "  2: {'reconstructed_action': 'pick-up Coke to landfill bin',\n",
       "   'action': 'pick-up',\n",
       "   'object': 'Coke',\n",
       "   'from_location': 'null',\n",
       "   'to_location': 'landfill bin',\n",
       "   'answer': 2},\n",
       "  3: {'reconstructed_action': 'pick-up Coke to recycling bin',\n",
       "   'action': 'pick-up',\n",
       "   'object': 'Coke',\n",
       "   'from_location': 'null',\n",
       "   'to_location': 'recycling bin',\n",
       "   'answer': 3},\n",
       "  4: {'reconstructed_action': 'pick-up sprite',\n",
       "   'action': 'pick-up',\n",
       "   'object': 'sprite',\n",
       "   'from_location': 'null',\n",
       "   'to_location': 'null',\n",
       "   'answer': 4}},\n",
       " 'right_answer': -1,\n",
       " 'new_vanilla_output': [{'action': 4, 'confidence': 1.0}],\n",
       " 'new_cot_output': [{'action': 0, 'confidence': 1.0}],\n",
       " 'new_self_probing_output': [{'action': 0, 'confidence': 1.0}],\n",
       " 'new_self_probing_output_log': [{'action': 0, 'confidence': 0.0}],\n",
       " 'new_multi_step_output': [{'action': 0, 'confidence': 1.0}],\n",
       " 'new_top_k_output': [{'action': 2,\n",
       "   'confidence': 0.0,\n",
       "   'all_result': {1: {'action': 2, 'confidence': 0.0},\n",
       "    2: {'action': 3, 'confidence': 0.0},\n",
       "    3: {'action': 0, 'confidence': 0.0},\n",
       "    4: {'action': 2, 'confidence': 0.0},\n",
       "    5: {'action': 0, 'confidence': 0.0},\n",
       "    6: {'action': 1, 'confidence': 0.0},\n",
       "    7: {'action': 1, 'confidence': 0.0},\n",
       "    8: {'action': 2, 'confidence': 0.0},\n",
       "    9: {'action': 3, 'confidence': 0.0},\n",
       "    10: {'action': 0, 'confidence': 0.0},\n",
       "    11: {'action': 2, 'confidence': 0.0},\n",
       "    12: {'action': 0, 'confidence': 0.0},\n",
       "    13: {'action': 1, 'confidence': 0.0},\n",
       "    14: {'action': 1, 'confidence': 0.0},\n",
       "    15: {'action': 2, 'confidence': 0.0},\n",
       "    16: {'action': 3, 'confidence': 0.0},\n",
       "    17: {'action': 0, 'confidence': 0.0},\n",
       "    18: {'action': 2, 'confidence': 0.0},\n",
       "    19: {'action': 0, 'confidence': 0.0},\n",
       "    20: {'action': 1, 'confidence': 0.0},\n",
       "    21: {'action': 1, 'confidence': 0.0},\n",
       "    22: {'action': 0, 'confidence': 0.0},\n",
       "    23: {'action': 2, 'confidence': 0.0},\n",
       "    24: {'action': 3, 'confidence': 0.0},\n",
       "    25: {'action': 0, 'confidence': 0.0},\n",
       "    26: {'action': 2, 'confidence': 0.0},\n",
       "    27: {'action': 0, 'confidence': 0.0},\n",
       "    28: {'action': 1, 'confidence': 0.0},\n",
       "    29: {'action': 1, 'confidence': 0.0},\n",
       "    30: {'action': 2, 'confidence': 0.0},\n",
       "    31: {'action': 3, 'confidence': 0.0},\n",
       "    32: {'action': 0, 'confidence': 0.0},\n",
       "    33: {'action': 2, 'confidence': 0.0},\n",
       "    34: {'action': 0, 'confidence': 0.0},\n",
       "    35: {'action': 1, 'confidence': 0.0},\n",
       "    36: {'action': 1, 'confidence': 0.0},\n",
       "    37: {'action': 0, 'confidence': 0.0},\n",
       "    38: {'action': 2, 'confidence': 0.0},\n",
       "    39: {'action': 3, 'confidence': 0.0},\n",
       "    40: {'action': 0, 'confidence': 0.0},\n",
       "    41: {'action': 2, 'confidence': 0.0},\n",
       "    42: {'action': 0, 'confidence': 0.0},\n",
       "    43: {'action': 1, 'confidence': 0.0},\n",
       "    44: {'action': 1, 'confidence': 0.0},\n",
       "    45: {'action': 0, 'confidence': 0.0},\n",
       "    46: {'action': 2, 'confidence': 0.0},\n",
       "    47: {'action': 3, 'confidence': 0.0},\n",
       "    48: {'action': 0, 'confidence': 0.0},\n",
       "    49: {'action': 2, 'confidence': 0.0},\n",
       "    50: {'action': 0, 'confidence': 0.0},\n",
       "    51: {'action': 1, 'confidence': 0.0},\n",
       "    52: {'action': 1, 'confidence': 0.0},\n",
       "    53: {'action': 0, 'confidence': 0.0},\n",
       "    54: {'action': 2, 'confidence': 0.0},\n",
       "    55: {'action': 3, 'confidence': 0.0},\n",
       "    56: {'action': 0, 'confidence': 0.0},\n",
       "    57: {'action': 2, 'confidence': 0.0},\n",
       "    58: {'action': 0, 'confidence': 0.0},\n",
       "    59: {'action': 1, 'confidence': 0.0},\n",
       "    60: {'action': 1, 'confidence': 0.0},\n",
       "    61: {'action': 0, 'confidence': 0.0},\n",
       "    62: {'action': 2, 'confidence': 0.0},\n",
       "    63: {'action': 3, 'confidence': 0.0},\n",
       "    64: {'action': 0, 'confidence': 0.0},\n",
       "    65: {'action': 2, 'confidence': 0.0}}}],\n",
       " 'new_conformal_output': [{'all_result': {1: {'action': 'pick up the sprite',\n",
       "     'confidence': np.float64(0.22700450950435774)},\n",
       "    2: {'action': 'pick up the coke',\n",
       "     'confidence': np.float64(0.21458799917120278)},\n",
       "    3: {'action': 'pick up the bottled water',\n",
       "     'confidence': np.float64(0.2127517848375339)},\n",
       "    4: {'action': 'an option not listed here',\n",
       "     'confidence': np.float64(0.18878238142355436)},\n",
       "    5: {'action': 'pick up the bottled unsweetened tea',\n",
       "     'confidence': np.float64(0.15687332506335136)}},\n",
       "   'action': 4,\n",
       "   'confidence': np.float64(0.22700450950435774)}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
